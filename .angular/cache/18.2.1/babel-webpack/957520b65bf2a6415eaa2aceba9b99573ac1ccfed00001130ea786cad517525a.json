{"ast":null,"code":"'use strict';\n\nconst tokenizer = require('./tokenizer.cjs');\nconst TAB = 9;\nconst N = 10;\nconst F = 12;\nconst R = 13;\nconst SPACE = 32;\nconst EXCLAMATIONMARK = 33; // !\nconst NUMBERSIGN = 35; // #\nconst AMPERSAND = 38; // &\nconst APOSTROPHE = 39; // '\nconst LEFTPARENTHESIS = 40; // (\nconst RIGHTPARENTHESIS = 41; // )\nconst ASTERISK = 42; // *\nconst PLUSSIGN = 43; // +\nconst COMMA = 44; // ,\nconst HYPERMINUS = 45; // -\nconst LESSTHANSIGN = 60; // <\nconst GREATERTHANSIGN = 62; // >\nconst QUESTIONMARK = 63; // ?\nconst COMMERCIALAT = 64; // @\nconst LEFTSQUAREBRACKET = 91; // [\nconst RIGHTSQUAREBRACKET = 93; // ]\nconst LEFTCURLYBRACKET = 123; // {\nconst VERTICALLINE = 124; // |\nconst RIGHTCURLYBRACKET = 125; // }\nconst INFINITY = 8734; // ∞\nconst NAME_CHAR = new Uint8Array(128).map((_, idx) => /[a-zA-Z0-9\\-]/.test(String.fromCharCode(idx)) ? 1 : 0);\nconst COMBINATOR_PRECEDENCE = {\n  ' ': 1,\n  '&&': 2,\n  '||': 3,\n  '|': 4\n};\nfunction scanSpaces(tokenizer) {\n  return tokenizer.substringToPos(tokenizer.findWsEnd(tokenizer.pos));\n}\nfunction scanWord(tokenizer) {\n  let end = tokenizer.pos;\n  for (; end < tokenizer.str.length; end++) {\n    const code = tokenizer.str.charCodeAt(end);\n    if (code >= 128 || NAME_CHAR[code] === 0) {\n      break;\n    }\n  }\n  if (tokenizer.pos === end) {\n    tokenizer.error('Expect a keyword');\n  }\n  return tokenizer.substringToPos(end);\n}\nfunction scanNumber(tokenizer) {\n  let end = tokenizer.pos;\n  for (; end < tokenizer.str.length; end++) {\n    const code = tokenizer.str.charCodeAt(end);\n    if (code < 48 || code > 57) {\n      break;\n    }\n  }\n  if (tokenizer.pos === end) {\n    tokenizer.error('Expect a number');\n  }\n  return tokenizer.substringToPos(end);\n}\nfunction scanString(tokenizer) {\n  const end = tokenizer.str.indexOf('\\'', tokenizer.pos + 1);\n  if (end === -1) {\n    tokenizer.pos = tokenizer.str.length;\n    tokenizer.error('Expect an apostrophe');\n  }\n  return tokenizer.substringToPos(end + 1);\n}\nfunction readMultiplierRange(tokenizer) {\n  let min = null;\n  let max = null;\n  tokenizer.eat(LEFTCURLYBRACKET);\n  min = scanNumber(tokenizer);\n  if (tokenizer.charCode() === COMMA) {\n    tokenizer.pos++;\n    if (tokenizer.charCode() !== RIGHTCURLYBRACKET) {\n      max = scanNumber(tokenizer);\n    }\n  } else {\n    max = min;\n  }\n  tokenizer.eat(RIGHTCURLYBRACKET);\n  return {\n    min: Number(min),\n    max: max ? Number(max) : 0\n  };\n}\nfunction readMultiplier(tokenizer) {\n  let range = null;\n  let comma = false;\n  switch (tokenizer.charCode()) {\n    case ASTERISK:\n      tokenizer.pos++;\n      range = {\n        min: 0,\n        max: 0\n      };\n      break;\n    case PLUSSIGN:\n      tokenizer.pos++;\n      range = {\n        min: 1,\n        max: 0\n      };\n      break;\n    case QUESTIONMARK:\n      tokenizer.pos++;\n      range = {\n        min: 0,\n        max: 1\n      };\n      break;\n    case NUMBERSIGN:\n      tokenizer.pos++;\n      comma = true;\n      if (tokenizer.charCode() === LEFTCURLYBRACKET) {\n        range = readMultiplierRange(tokenizer);\n      } else if (tokenizer.charCode() === QUESTIONMARK) {\n        // https://www.w3.org/TR/css-values-4/#component-multipliers\n        // > the # and ? multipliers may be stacked as #?\n        // In this case just treat \"#?\" as a single multiplier\n        // { min: 0, max: 0, comma: true }\n        tokenizer.pos++;\n        range = {\n          min: 0,\n          max: 0\n        };\n      } else {\n        range = {\n          min: 1,\n          max: 0\n        };\n      }\n      break;\n    case LEFTCURLYBRACKET:\n      range = readMultiplierRange(tokenizer);\n      break;\n    default:\n      return null;\n  }\n  return {\n    type: 'Multiplier',\n    comma,\n    min: range.min,\n    max: range.max,\n    term: null\n  };\n}\nfunction maybeMultiplied(tokenizer, node) {\n  const multiplier = readMultiplier(tokenizer);\n  if (multiplier !== null) {\n    multiplier.term = node;\n\n    // https://www.w3.org/TR/css-values-4/#component-multipliers\n    // > The + and # multipliers may be stacked as +#;\n    // Represent \"+#\" as nested multipliers:\n    // { ...<multiplier #>,\n    //   term: {\n    //     ...<multipler +>,\n    //     term: node\n    //   }\n    // }\n    if (tokenizer.charCode() === NUMBERSIGN && tokenizer.charCodeAt(tokenizer.pos - 1) === PLUSSIGN) {\n      return maybeMultiplied(tokenizer, multiplier);\n    }\n    return multiplier;\n  }\n  return node;\n}\nfunction maybeToken(tokenizer) {\n  const ch = tokenizer.peek();\n  if (ch === '') {\n    return null;\n  }\n  return {\n    type: 'Token',\n    value: ch\n  };\n}\nfunction readProperty(tokenizer) {\n  let name;\n  tokenizer.eat(LESSTHANSIGN);\n  tokenizer.eat(APOSTROPHE);\n  name = scanWord(tokenizer);\n  tokenizer.eat(APOSTROPHE);\n  tokenizer.eat(GREATERTHANSIGN);\n  return maybeMultiplied(tokenizer, {\n    type: 'Property',\n    name\n  });\n}\n\n// https://drafts.csswg.org/css-values-3/#numeric-ranges\n// 4.1. Range Restrictions and Range Definition Notation\n//\n// Range restrictions can be annotated in the numeric type notation using CSS bracketed\n// range notation—[min,max]—within the angle brackets, after the identifying keyword,\n// indicating a closed range between (and including) min and max.\n// For example, <integer [0, 10]> indicates an integer between 0 and 10, inclusive.\nfunction readTypeRange(tokenizer) {\n  // use null for Infinity to make AST format JSON serializable/deserializable\n  let min = null; // -Infinity\n  let max = null; // Infinity\n  let sign = 1;\n  tokenizer.eat(LEFTSQUAREBRACKET);\n  if (tokenizer.charCode() === HYPERMINUS) {\n    tokenizer.peek();\n    sign = -1;\n  }\n  if (sign == -1 && tokenizer.charCode() === INFINITY) {\n    tokenizer.peek();\n  } else {\n    min = sign * Number(scanNumber(tokenizer));\n    if (NAME_CHAR[tokenizer.charCode()] !== 0) {\n      min += scanWord(tokenizer);\n    }\n  }\n  scanSpaces(tokenizer);\n  tokenizer.eat(COMMA);\n  scanSpaces(tokenizer);\n  if (tokenizer.charCode() === INFINITY) {\n    tokenizer.peek();\n  } else {\n    sign = 1;\n    if (tokenizer.charCode() === HYPERMINUS) {\n      tokenizer.peek();\n      sign = -1;\n    }\n    max = sign * Number(scanNumber(tokenizer));\n    if (NAME_CHAR[tokenizer.charCode()] !== 0) {\n      max += scanWord(tokenizer);\n    }\n  }\n  tokenizer.eat(RIGHTSQUAREBRACKET);\n  return {\n    type: 'Range',\n    min,\n    max\n  };\n}\nfunction readType(tokenizer) {\n  let name;\n  let opts = null;\n  tokenizer.eat(LESSTHANSIGN);\n  name = scanWord(tokenizer);\n  if (tokenizer.charCode() === LEFTPARENTHESIS && tokenizer.nextCharCode() === RIGHTPARENTHESIS) {\n    tokenizer.pos += 2;\n    name += '()';\n  }\n  if (tokenizer.charCodeAt(tokenizer.findWsEnd(tokenizer.pos)) === LEFTSQUAREBRACKET) {\n    scanSpaces(tokenizer);\n    opts = readTypeRange(tokenizer);\n  }\n  tokenizer.eat(GREATERTHANSIGN);\n  return maybeMultiplied(tokenizer, {\n    type: 'Type',\n    name,\n    opts\n  });\n}\nfunction readKeywordOrFunction(tokenizer) {\n  const name = scanWord(tokenizer);\n  if (tokenizer.charCode() === LEFTPARENTHESIS) {\n    tokenizer.pos++;\n    return {\n      type: 'Function',\n      name\n    };\n  }\n  return maybeMultiplied(tokenizer, {\n    type: 'Keyword',\n    name\n  });\n}\nfunction regroupTerms(terms, combinators) {\n  function createGroup(terms, combinator) {\n    return {\n      type: 'Group',\n      terms,\n      combinator,\n      disallowEmpty: false,\n      explicit: false\n    };\n  }\n  let combinator;\n  combinators = Object.keys(combinators).sort((a, b) => COMBINATOR_PRECEDENCE[a] - COMBINATOR_PRECEDENCE[b]);\n  while (combinators.length > 0) {\n    combinator = combinators.shift();\n    let i = 0;\n    let subgroupStart = 0;\n    for (; i < terms.length; i++) {\n      const term = terms[i];\n      if (term.type === 'Combinator') {\n        if (term.value === combinator) {\n          if (subgroupStart === -1) {\n            subgroupStart = i - 1;\n          }\n          terms.splice(i, 1);\n          i--;\n        } else {\n          if (subgroupStart !== -1 && i - subgroupStart > 1) {\n            terms.splice(subgroupStart, i - subgroupStart, createGroup(terms.slice(subgroupStart, i), combinator));\n            i = subgroupStart + 1;\n          }\n          subgroupStart = -1;\n        }\n      }\n    }\n    if (subgroupStart !== -1 && combinators.length) {\n      terms.splice(subgroupStart, i - subgroupStart, createGroup(terms.slice(subgroupStart, i), combinator));\n    }\n  }\n  return combinator;\n}\nfunction readImplicitGroup(tokenizer) {\n  const terms = [];\n  const combinators = {};\n  let token;\n  let prevToken = null;\n  let prevTokenPos = tokenizer.pos;\n  while (token = peek(tokenizer)) {\n    if (token.type !== 'Spaces') {\n      if (token.type === 'Combinator') {\n        // check for combinator in group beginning and double combinator sequence\n        if (prevToken === null || prevToken.type === 'Combinator') {\n          tokenizer.pos = prevTokenPos;\n          tokenizer.error('Unexpected combinator');\n        }\n        combinators[token.value] = true;\n      } else if (prevToken !== null && prevToken.type !== 'Combinator') {\n        combinators[' '] = true; // a b\n        terms.push({\n          type: 'Combinator',\n          value: ' '\n        });\n      }\n      terms.push(token);\n      prevToken = token;\n      prevTokenPos = tokenizer.pos;\n    }\n  }\n\n  // check for combinator in group ending\n  if (prevToken !== null && prevToken.type === 'Combinator') {\n    tokenizer.pos -= prevTokenPos;\n    tokenizer.error('Unexpected combinator');\n  }\n  return {\n    type: 'Group',\n    terms,\n    combinator: regroupTerms(terms, combinators) || ' ',\n    disallowEmpty: false,\n    explicit: false\n  };\n}\nfunction readGroup(tokenizer) {\n  let result;\n  tokenizer.eat(LEFTSQUAREBRACKET);\n  result = readImplicitGroup(tokenizer);\n  tokenizer.eat(RIGHTSQUAREBRACKET);\n  result.explicit = true;\n  if (tokenizer.charCode() === EXCLAMATIONMARK) {\n    tokenizer.pos++;\n    result.disallowEmpty = true;\n  }\n  return result;\n}\nfunction peek(tokenizer) {\n  let code = tokenizer.charCode();\n  if (code < 128 && NAME_CHAR[code] === 1) {\n    return readKeywordOrFunction(tokenizer);\n  }\n  switch (code) {\n    case RIGHTSQUAREBRACKET:\n      // don't eat, stop scan a group\n      break;\n    case LEFTSQUAREBRACKET:\n      return maybeMultiplied(tokenizer, readGroup(tokenizer));\n    case LESSTHANSIGN:\n      return tokenizer.nextCharCode() === APOSTROPHE ? readProperty(tokenizer) : readType(tokenizer);\n    case VERTICALLINE:\n      return {\n        type: 'Combinator',\n        value: tokenizer.substringToPos(tokenizer.pos + (tokenizer.nextCharCode() === VERTICALLINE ? 2 : 1))\n      };\n    case AMPERSAND:\n      tokenizer.pos++;\n      tokenizer.eat(AMPERSAND);\n      return {\n        type: 'Combinator',\n        value: '&&'\n      };\n    case COMMA:\n      tokenizer.pos++;\n      return {\n        type: 'Comma'\n      };\n    case APOSTROPHE:\n      return maybeMultiplied(tokenizer, {\n        type: 'String',\n        value: scanString(tokenizer)\n      });\n    case SPACE:\n    case TAB:\n    case N:\n    case R:\n    case F:\n      return {\n        type: 'Spaces',\n        value: scanSpaces(tokenizer)\n      };\n    case COMMERCIALAT:\n      code = tokenizer.nextCharCode();\n      if (code < 128 && NAME_CHAR[code] === 1) {\n        tokenizer.pos++;\n        return {\n          type: 'AtKeyword',\n          name: scanWord(tokenizer)\n        };\n      }\n      return maybeToken(tokenizer);\n    case ASTERISK:\n    case PLUSSIGN:\n    case QUESTIONMARK:\n    case NUMBERSIGN:\n    case EXCLAMATIONMARK:\n      // prohibited tokens (used as a multiplier start)\n      break;\n    case LEFTCURLYBRACKET:\n      // LEFTCURLYBRACKET is allowed since mdn/data uses it w/o quoting\n      // check next char isn't a number, because it's likely a disjoined multiplier\n      code = tokenizer.nextCharCode();\n      if (code < 48 || code > 57) {\n        return maybeToken(tokenizer);\n      }\n      break;\n    default:\n      return maybeToken(tokenizer);\n  }\n}\nfunction parse(source) {\n  const tokenizer$1 = new tokenizer.Tokenizer(source);\n  const result = readImplicitGroup(tokenizer$1);\n  if (tokenizer$1.pos !== source.length) {\n    tokenizer$1.error('Unexpected input');\n  }\n\n  // reduce redundant groups with single group term\n  if (result.terms.length === 1 && result.terms[0].type === 'Group') {\n    return result.terms[0];\n  }\n  return result;\n}\nexports.parse = parse;","map":null,"metadata":{},"sourceType":"script","externalDependencies":[]}